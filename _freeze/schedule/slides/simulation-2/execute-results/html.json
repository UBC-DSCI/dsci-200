{
  "hash": "f9832d8afaa7a90118d27ee87eb4999f",
  "result": {
    "engine": "knitr",
    "markdown": "---\nlecture: \"Simulations-II\"\nformat: revealjs\nmetadata-files: \n  - _metadata.yml\n---\n\n\n## {{< meta lecture >}} {.large background-image=\"img/smooths.png\" background-opacity=\"0.3\" background-size=\"50%\"}\n\n[DSCI 200]{.secondary}\n\n[{{< meta author >}}]{.secondary}\n\nLast modified -- 21 January 2026\n\n\n\n\n\n$$\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\find}{find}\n\\DeclareMathOperator{\\st}{subject\\,\\,to}\n\\newcommand{\\E}{E}\n\\newcommand{\\Expect}[1]{\\E\\left[ #1 \\right]}\n\\newcommand{\\Var}[1]{\\mathrm{Var}\\left[ #1 \\right]}\n\\newcommand{\\Cov}[2]{\\mathrm{Cov}\\left[#1,\\ #2\\right]}\n\\newcommand{\\given}{\\ \\vert\\ }\n\\newcommand{\\X}{\\mathbf{X}}\n\\newcommand{\\x}{\\mathbf{x}}\n\\newcommand{\\y}{\\mathbf{y}}\n\\newcommand{\\P}{\\mathcal{P}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\n\\newcommand{\\snorm}[1]{\\lVert #1 \\rVert}\n\\newcommand{\\tr}[1]{\\mbox{tr}(#1)}\n\\newcommand{\\brt}{\\widehat{\\beta}^R_{s}}\n\\newcommand{\\brl}{\\widehat{\\beta}^R_{\\lambda}}\n\\newcommand{\\bls}{\\widehat{\\beta}_{ols}}\n\\newcommand{\\blt}{\\widehat{\\beta}^L_{s}}\n\\newcommand{\\bll}{\\widehat{\\beta}^L_{\\lambda}}\n\\newcommand{\\U}{\\mathbf{U}}\n\\newcommand{\\D}{\\mathbf{D}}\n\\newcommand{\\V}{\\mathbf{V}}\n$$\n\n\n\n\n## Attribution\n<br><br>\n\n*Some of the material is based on content adapted from* \n\n- [*Chapter 20 of R Programming for Data Science, by R. Peng*](https://bookdown.org/rdpeng/rprogdatascience/simulation.html#generating-random-numbers)\n\n<br><br>\n\n## Learning Objectives \n<br><br>\n\n- Understand the mechanisms for generating and simulating data.\n- Contrast empirical and theoretical distributions.\n- Use simulations to approximate probability of events or distribution functions.\n- Use simulations to assess theoretical properties of random variables.\n- Explore the Central Limit Theorem (CLT) and Law of Large Numbers (LLN).\n- Write reproducible simulation code.\n- Interpret and reflect on simulation results using plots and summary statistics. \n\n## Last time: Simulations\n\nDefine the main steps of a simulation:\n\n- 1. Define **the process** we want to simulate\n\n- 2. Specify how **randomness** enters the process\n\n- 3. Decide **what to record** from each run\n\n- 4. **Repeat** the process many times\n\n- 5. **Summarize** the results across runs\n\nWe used simulation to approximate two probabilities when randomness came from a physical event\n\n#### Today, we’ll use simulations to study properties of estimators and generate randomness from sampling and using distributions!!\n\n\n## Sampling from a finite population\n\nIn lecture 3, we sampled from the `wildfire` population and compared population parameters with sample estimators.\n\n- Population parameters are unknown but fixed\n\n- Sample estimators are random since they are based on a random sample.\n\n#### Every time we select a new random sample we get a different estimate.\n\n## The Wildfire Population\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(infer)\nlibrary(readr)\n\nwildfire <- read_csv(\"data/wildfire.csv\")\n\nhead(wildfire)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 35\n   year fire_number current_size size_class latitude longitude fire_origin    \n  <dbl> <chr>              <dbl> <chr>         <dbl>     <dbl> <chr>          \n1  2006 PWF001              0.1  A              56.2     -117. Land Owner     \n2  2006 EWF002              0.2  B              53.6     -116. Fire Department\n3  2006 EWF001              0.5  B              53.6     -116. Fire Department\n4  2006 EWF003              0.01 A              53.6     -116. Industry       \n5  2006 PWF002              0.1  A              56.2     -117. Fire Department\n6  2006 CWF001              0.2  B              51.2     -115. Fire Department\n# ℹ 28 more variables: general_cause <chr>, responsible_group <chr>,\n#   activity_class <chr>, true_cause <chr>, fire_start_date <dttm>,\n#   detection_agent_type <chr>, detection_agent <chr>,\n#   assessment_hectares <dbl>, fire_spread_rate <dbl>, fire_type <chr>,\n#   fire_position_on_slope <chr>, weather_conditions_over_fire <chr>,\n#   temperature <dbl>, relative_humidity <dbl>, wind_direction <chr>,\n#   wind_speed <dbl>, fuel_type <chr>, initial_action_by <chr>, …\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(wildfire)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 26551    35\n```\n\n\n:::\n:::\n\n\n\n#### We'll focus on the numerical variable `temperature`\n\n## Population parameters for `temperature`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwildfire |>\n  summarise(\n    mean_temp = mean(temperature, na.rm = TRUE),\n    med_temp = median(temperature, na.rm = TRUE),\n    var_temp = var(temperature, na.rm = TRUE),\n    sd_temp = sd(temperature, na.rm = TRUE),\n    min_temp = min(temperature, na.rm = TRUE),\n    max_temp = max(temperature, na.rm = TRUE)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  mean_temp med_temp var_temp sd_temp min_temp max_temp\n      <dbl>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>\n1      17.9       19     60.1    7.75      -39       45\n```\n\n\n:::\n:::\n\n\n\n## A random sample and sample estimates\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(200)\n\nwildfire_sample <- wildfire |> rep_sample_n(size = 100)\n\ntemperature_rv <- wildfire_sample$temperature\n  \nc(x_bar = mean(temperature_rv, na.rm = TRUE), \n  s = sd(temperature_rv, na.rm = TRUE))  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    x_bar         s \n17.118681  7.236496 \n```\n\n\n:::\n:::\n\n\n\n## Temperature as a random variable\n\nEvery time we take a new sample, the values of `temperature` change.\n\n> `temperature` is a random variable and randomness comes from sampling!\n\nAny statistic of `temperature` becomes a random variable as well. \n\n> for example, the mean temperature ($\\bar{x}$) is a random variable\n\n#### The changes in point estimates across samples is called **sampling variability**\n\n## Standard errors\n\nThe standard error of an estimator measures how much the sample estimate (like the mean) is expected to vary across different random samples.\n\nIn lecture 3 we said that the standard error of the sample mean is given by:  \n\n$$SE(\\bar{x}) = \\frac{\\sigma}{\\sqrt{n}}$$\nand the population parameter $\\sigma$ can be estimated with the sample standard deviation $s$.\n\n## Let's build a simulation\n\n<br>\n\nLet's use simulation to study the variability of the sample mean (standard error) when sampling from a finite population.\n\n- 1. Define **the process** we want to simulate\n\n- 2. Specify how **randomness** enters the process\n\n- 3. Decide **what to record** from each run\n\n- 4. **Repeat** the process many times\n\n- 5. **Summarize** the results across runs\n\n## iClicker 1: simulation design\n\nWhich of the following options best describes a simulation study?\n\n- A. Drawing a single sample from the population and computing the mean of temperature in the sample\n\n- B. Drawing many samples from the population and computing the mean of temperature in each sample \n\n- C. Computing the mean of temperature from the full population\n\n- D. Generating temperature values from a Normal distribution and computing its mean\n\n## in R\n\n1. Take a random sample of size $n = 7000$\n2. Compute the sample mean temperature\n3. Repeat this 1000 times\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(200)\n\npop_temp_complete <- wildfire |>\n select(temperature)  |>\n drop_na()  \n\nn <- 7000\nN <- length(pop_temp_complete)\n\n# sample_mean_reps <- pop_temp_complete |>\n# ...(size = ..., reps = ...) |> \n#\tgroup_by(...) |> \n#\tsummarise(temp_mean = ...(..., na.rm=TRUE))\n```\n:::\n\n\n\n\n#### We now have a list of 1000 sample mean temperatures!\n\n\n## Summarize\n\nWe can use the list of sample estimates to study the\nsampling variability.\n\n> Let's approximate the SE computing the standard deviation of the sample estimates\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# se_simulation <- ...(sampling_dist$sample_mean)\n# se_formula <- ...(pop_temp_complete$...)/...\n```\n:::\n\n\n\n#### Something seems off ....\n\n## Sampling from a finite population\n\n- When sampling without replacement from a finite population observations are not independent.\n\n- The variability of the sample mean is smaller than in model-based sampling.\n\n- This reduction in variability is captured by the finite population correction (FPC):\n\n$$ SE(\\bar{x}) = \\frac{\\sigma}{\\sqrt{n}}*\\sqrt{1-\\frac{n}{N}}\n$$\n\nwhere $N$ and $n$ are the population and the sample sizes, respectively.\n\n##\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyr)\n\ncum_sd <- sapply(\n  seq_along(sample_mean_reps$temp_mean),\n  function(k) sd(sample_mean_reps$temp_mean[1:k])\n)\n\nmean_temp_df <- data.frame(\n  runs = seq_along(sample_mean_reps$temp_mean),\n  se_mean_temp  = cum_sd\n)\n\nmean_temp_long <- tidyr::pivot_longer(\n  mean_temp_df,\n  -runs,\n  names_to = \"event\",\n  values_to = \"estimate\"\n)\n\nfcp <- sqrt(1 - (n / N))\nse_corrected_fpc <- se_formula *fcp\n\nref_lines <- data.frame(\n  se = c(se_simulation, se_corrected_fpc, se_formula),\n  method = c(\"Simulation SD\", \"FPC-corrected formula\", \"Uncorrected formula\")\n)\n\nt_long_run <- ggplot(mean_temp_long, aes(x = runs, y = estimate, color = event)) +\n  geom_line() +\n  geom_hline(\n    data = ref_lines,\n    aes(yintercept = se, color = method),\n    linetype = \"dashed\"\n  ) +\n  scale_color_manual(\n    values = c(\n      \"Simulation SD\" = \"#F8766D\",        \n      \"FPC-corrected formula\" = \"#00BA38\", \n      \"Uncorrected formula\" = \"#619CFF\" \n    )\n  ) +\n  labs(\n    x = \"Number of simulation runs\",\n    y = \"Estimated SE\",\n    color = \"\",\n    title = \"Estimated SE of mean temperature\"\n  )\n```\n:::\n\n\n\n## Generating values from a distribution\n\nAnother way of generating randon numbers is using  well-known probability distributions like the Normal, Poisson, and binomial. \n\n### in R\n\n- `rnorm`: generate random Normal variates \n  - arguments: `n` (sample size), `mean` and `sd`\n\n- `rpois`: generate random Poisson variates \n  - arguments: `n`, `lambda` (rate)\n  \n- `runif`: generate random Uniform variates \n  - arguments: `n`, `min`, `max` (interval)\n\n- `rbinom`: generate random binomial variates \n  - arguments: `n`, `size`, `prob`\n\n## Example\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nx <- runif(10, 2, 5) \nx\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 3.601317 3.751295 3.768735 4.073120 4.001994 4.517881 4.134800 2.289504\n [9] 3.571474 2.706052\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.290   3.579   3.760   3.642   4.055   4.518 \n```\n\n\n:::\n:::\n\n\n\n#### Everytime we run this code, it generates new values\n\n## Setting the seed\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(200)\n\nrunif(5, 2, 5) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.601317 3.751295 3.768735 4.073120 4.001994\n```\n\n\n:::\n\n```{.r .cell-code}\nrnorm(2, 0, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.983119 -2.603497\n```\n\n\n:::\n\n```{.r .cell-code}\nrbinom(3, 1, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0 0 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# changing the sequence\n\nset.seed(200)\n\nrunif(5, 2, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.601317 3.751295 3.768735 4.073120 4.001994\n```\n\n\n:::\n\n```{.r .cell-code}\nrnorm(2, 0, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  1.983119 -2.603497\n```\n\n\n:::\n\n```{.r .cell-code}\nrpois(4,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 7 6 8 6\n```\n\n\n:::\n\n```{.r .cell-code}\nrbinom(3, 1, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0 0 0\n```\n\n\n:::\n:::\n\n\n\n## Simulate a simple linear regression (SLR)\n\n- 1) Simulate a dataset from the following model:\n\n$$y = \\beta_0 + \\beta_1 \\times x + \\varepsilon$$\nwhere $\\varepsilon \\sim \\mathcal{N}(0,1)$ and $x \\sim \\text{Unif}(1,3)$. \n\nIn your simulation, set the population coefficients $\\beta_0 = 1$ and $\\beta_1 = 2$. In real data, these are unknown and you use a sample to estimate them.\n\n- 2. Plot the data \n\n- 3. Use the function `lm()` to estimate the parameters of the model using least squares estimation\n\n> Check [this application](https://setosa.io/ev/ordinary-least-squares-regression/) to recall LS estimation\n\n## Key takeaways\n\n:::incremental\n\n- Simulations can be used to: \n  - approximate probabilities, \n  - study properties of estimators, \n  - approximate distributions\n\n- Randomness can be introduced using code that: \n  - mimics physical processes\n  - randomly select outcomes from a finite population\n  - generates random values from a distribution\n  \n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}