{
  "hash": "9005bc4307c8cc9c478c715d59577a93",
  "result": {
    "engine": "knitr",
    "markdown": "---\nlecture: \"Fundamentals of Sampling and Variability\"\nformat: revealjs\nmetadata-files: \n  - _metadata.yml\n---\n\n\n\n## {{< meta lecture >}} {.large background-image=\"img/smooths.png\" background-opacity=\"0.3\" background-size=\"50%\"}\n\n[DSCI 200]{.secondary}\n\n[{{< meta author >}}]{.secondary}\n\nLast modified -- 05 January 2026\n\n\n\n\n\n\n\n$$\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\argmax}{argmax}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\\DeclareMathOperator*{\\maximize}{maximize}\n\\DeclareMathOperator*{\\find}{find}\n\\DeclareMathOperator{\\st}{subject\\,\\,to}\n\\newcommand{\\E}{E}\n\\newcommand{\\Expect}[1]{\\E\\left[ #1 \\right]}\n\\newcommand{\\Var}[1]{\\mathrm{Var}\\left[ #1 \\right]}\n\\newcommand{\\Cov}[2]{\\mathrm{Cov}\\left[#1,\\ #2\\right]}\n\\newcommand{\\given}{\\ \\vert\\ }\n\\newcommand{\\X}{\\mathbf{X}}\n\\newcommand{\\x}{\\mathbf{x}}\n\\newcommand{\\y}{\\mathbf{y}}\n\\newcommand{\\P}{\\mathcal{P}}\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\norm}[1]{\\left\\lVert #1 \\right\\rVert}\n\\newcommand{\\snorm}[1]{\\lVert #1 \\rVert}\n\\newcommand{\\tr}[1]{\\mbox{tr}(#1)}\n\\newcommand{\\brt}{\\widehat{\\beta}^R_{s}}\n\\newcommand{\\brl}{\\widehat{\\beta}^R_{\\lambda}}\n\\newcommand{\\bls}{\\widehat{\\beta}_{ols}}\n\\newcommand{\\blt}{\\widehat{\\beta}^L_{s}}\n\\newcommand{\\bll}{\\widehat{\\beta}^L_{\\lambda}}\n\\newcommand{\\U}{\\mathbf{U}}\n\\newcommand{\\D}{\\mathbf{D}}\n\\newcommand{\\V}{\\mathbf{V}}\n$$\n\n\n\n\n\n\n\n\n\n\n## Attribution\n<br><br>\n\n*This material is adapted from* [*Chapters 5 of Elementary Statistics with R*](https://homerhanumat.github.io/elemStats/).\n\n<br><br>\n\n## Learning Objectives \n<br><br>\n\n- Distinguish between a population and a sample from a finite population. \n\n- Define commonly used population parameters and their corresponding point estimates.   \n\n- Identify the population, sample, parameters and point estimates in a given scenario. \n\n- Explain what sampling variability is and how it arises from samples drawn at random. \n\n- Define standard error of an estimator and describe how it relates to sampling variability.  \n\n\n## The Data: Wildfires in Alberta\n\n- Alberta has been heavily affected by wildfires in recent years. \n- Wildfires cause environmental, economic and social harm:\n  - Destruction of forests and infrastructure\n  - Widespread evacuations\n  - Disproportionate impacts on rural and Indigenous communities\n- Data helps us plan and respond more effectively and equitably.\n\n## Packages\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n#library(diversedata)\nlibrary(infer)\n```\n:::\n\n\n\n\n##\n\nWe will load `wildfire` data from the `diversedata` R package: \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwildfire <- read_csv(\"data/wildfire.csv\")\n\nhead(wildfire)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 35\n   year fire_number current_size size_class latitude longitude fire_origin    \n  <dbl> <chr>              <dbl> <chr>         <dbl>     <dbl> <chr>          \n1  2006 PWF001              0.1  A              56.2     -117. Land Owner     \n2  2006 EWF002              0.2  B              53.6     -116. Fire Department\n3  2006 EWF001              0.5  B              53.6     -116. Fire Department\n4  2006 EWF003              0.01 A              53.6     -116. Industry       \n5  2006 PWF002              0.1  A              56.2     -117. Fire Department\n6  2006 CWF001              0.2  B              51.2     -115. Fire Department\n# ℹ 28 more variables: general_cause <chr>, responsible_group <chr>,\n#   activity_class <chr>, true_cause <chr>, fire_start_date <dttm>,\n#   detection_agent_type <chr>, detection_agent <chr>,\n#   assessment_hectares <dbl>, fire_spread_rate <dbl>, fire_type <chr>,\n#   fire_position_on_slope <chr>, weather_conditions_over_fire <chr>,\n#   temperature <dbl>, relative_humidity <dbl>, wind_direction <chr>,\n#   wind_speed <dbl>, fuel_type <chr>, initial_action_by <chr>, …\n```\n\n\n:::\n\n```{.r .cell-code}\ndim(wildfire)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 26551    35\n```\n\n\n:::\n:::\n\n\n\n\n\n## Population \n\n::: columns\n::: {.column width=\"50%\"}\n\n- A <span class=\"secondary\">population</span> is a collection of all subjects or observations we are interested in (e.g., all UBC students).\n\n- For today's discussion, we will think of the wildfire data as a **finite population**, consisting of 26551 wildfire records in Alberta from 2006-2024.\n\n:::\n\n::: {.column width=\"50%\"}\n\n<div style=\"text-align: center;\">\n  <img src=\"img/wildfire.png\" alt=\"Wildfire map\" style=\"width: 65%; border-radius: 12px;\" />\n</div>\n\n<div style=\"text-align: center; font-size: 12px; margin-top: 0.5em;\">\n  Source: <a href=\"https://diverse-data-hub.github.io/website_files/description_pages/wildfire.html\" target=\"_blank\">diverse-data-hub.github.io</a>\n</div>\n\n:::\n:::\n\n\n## Temperature\n\n- Let's focus on all wildfire-related temperature values:\n  \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(wildfire, aes(x = temperature)) +\n  geom_histogram(binwidth = 2, fill = \"#1f78b4\", color = \"white\", alpha = 0.8) +\n  labs(title = \"Histogram of Wildfire Temperatures\", x = \"Temperature (°C)\", y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](sampling-fundamentals_files/figure-revealjs/unnamed-chunk-4-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n\n\n## Parameters\n\n- From our population distribution of temperature, we may want to compute some quantities (e.g., mean, median, standard deviations).\n- A **parameter** is a numerical quantity that describes the **population**.\n- Here are some parameters computed from our population of wildfire temperature's:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwildfire |>\n  summarise(\n    mean_temp = mean(temperature, na.rm = TRUE),\n    med_temp = median(temperature, na.rm = TRUE),\n    var_temp = var(temperature, na.rm = TRUE),\n    sd_temp = sd(temperature, na.rm = TRUE),\n    min_temp = min(temperature, na.rm = TRUE),\n    max_temp = max(temperature, na.rm = TRUE)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 6\n  mean_temp med_temp var_temp sd_temp min_temp max_temp\n      <dbl>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>\n1      17.9       19     60.1    7.75      -39       45\n```\n\n\n:::\n:::\n\n\n\n\n## Sample \n\n- In practice, it is fairly uncommon to have data on the entire population. \n\n- A <span class=\"secondary\">sample</span> is a subset of of our population that we will use to draw conclusions about the larger population. \n\n<div style=\"text-align: center;\">\n  <img src=\"https://www.scribbr.com/wp-content/uploads/2019/09/population-vs-sample-1.png\" style=\"width: 30%;\">\n</div>\n\n<div style=\"font-size: 0.6em; text-align: center; color: gray;\">\nSource: <a href=\"https://www.scribbr.com/methodology/population-vs-sample/\" target=\"_blank\">Scribbr: Population vs. Sample</a>\n</div>\n\n## Sample Wildfire Data\n\nInstead of looking at the whole population, let's take a sample of size $n=100$. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(200)\n\nwildfire_sample <- wildfire |> rep_sample_n(size = 100)\nhead(wildfire_sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 36\n# Groups:   replicate [1]\n  replicate  year fire_number current_size size_class latitude longitude\n      <int> <dbl> <chr>              <dbl> <chr>         <dbl>     <dbl>\n1         1  2007 HWF214             33.5  C              59.2     -117.\n2         1  2008 SWF264              0.02 A              56       -113.\n3         1  2008 GWF129              0.2  B              55.1     -117.\n4         1  2014 EWF011              0.01 A              53.5     -117.\n5         1  2012 PWF134              0.01 A              57.6     -118.\n6         1  2021 LWF166              0.01 A              54.9     -112.\n# ℹ 29 more variables: fire_origin <chr>, general_cause <chr>,\n#   responsible_group <chr>, activity_class <chr>, true_cause <chr>,\n#   fire_start_date <dttm>, detection_agent_type <chr>, detection_agent <chr>,\n#   assessment_hectares <dbl>, fire_spread_rate <dbl>, fire_type <chr>,\n#   fire_position_on_slope <chr>, weather_conditions_over_fire <chr>,\n#   temperature <dbl>, relative_humidity <dbl>, wind_direction <chr>,\n#   wind_speed <dbl>, fuel_type <chr>, initial_action_by <chr>, …\n```\n\n\n:::\n:::\n\n\n\n\n## Statistics\n\n- Now, from our sample distribution of temperature, we may want to compute some numerical quantities as we did before.\n- A **statistic** is a numerical quantity that describes the **sample**. Alternatively, when we are using a value to estimate a population parameter, they are often referred to as *point estimates*. \n- Here are some statistics computed from our population of wildfire temperature's:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwildfire_sample |>\n  summarise(\n    mean_temp = mean(temperature, na.rm = TRUE),\n    med_temp = median(temperature, na.rm = TRUE),\n    var_temp = var(temperature, na.rm = TRUE),\n    sd_temp = sd(temperature, na.rm = TRUE),\n    min_temp = min(temperature, na.rm = TRUE),\n    max_temp = max(temperature, na.rm = TRUE), .groups = \"drop\"\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 7\n  replicate mean_temp med_temp var_temp sd_temp min_temp max_temp\n      <int>     <dbl>    <dbl>    <dbl>   <dbl>    <dbl>    <dbl>\n1         1      17.1       18     52.4    7.24       -3       30\n```\n\n\n:::\n:::\n\n\n\n## Common parameters and their point estimates\n\n| Population Parameter | Description                    | Point Estimate | Description                     |\n|------------------------------|--------------------------------|-----------------------|---------------------------------|\n| $\\mu$                        | Population mean                | $\\bar{x}$             | Sample mean    |\n| $\\tilde{\\mu}$ or $M$          | Population median              | $\\tilde{x}$           | Sample median  |\n| $\\sigma$                     | Population standard deviation  | $s$                   | Sample standard deviation|\n| $p$                          | Population proportion          | $\\hat{p}$             | Sample proportion  |\n| $\\rho$                       | Population correlation         | $r$                   | Sample correlation  |\n## iClicker: Another sample\n\nSuppose we take a **new random sample** of size $n = 100$ from the wildfire data and we calculate the mean temperature again.  What do you expect?\n\n- A) The new sample mean will be the same as before  \n- B) The new sample mean will likely be a little different, but close to the first one  \n- C) The new sample mean has no relationship with the first one \n- D) We need more information \n\n\n## Computing another sample\n\n- We can see that in a new sample of size 100 the sample mean of 17.19 is quite close to our previous sample mean of 17.11, although they aren't exactly the same. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(123)\n\nwildfire_sample2 <- wildfire |> rep_sample_n(size = 100)\nwildfire_sample2 |>\n  summarise(\n    mean_temp = mean(temperature, na.rm = TRUE)\n  ) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  replicate mean_temp\n      <int>     <dbl>\n1         1      17.2\n```\n\n\n:::\n:::\n\n\n\n\n##\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#| echo: false\n#| autorun: true\n#| fig-width: 7\n#| fig-height: 4\n\nlibrary(tidyverse)\n\nwildfire <- read_csv(\"data/wildfire.csv\")\nwildfire <- wildfire |> drop_na()\n\nset.seed(123)\n\nwildfire_sample2 <- wildfire |> rep_sample_n(size = 100)\nwildfire_sample2 |>\n  select(temperature) |>\n  summarise(\n    mean_temp = mean(temperature, na.rm = TRUE)\n  ) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  replicate mean_temp\n      <int>     <dbl>\n1         1      18.6\n```\n\n\n:::\n\n```{.r .cell-code}\n# Label each sample\nsample1_labeled <- wildfire_sample |> mutate(sample = \"Sample 1\")\nsample2_labeled <- wildfire_sample2 |> mutate(sample = \"Sample 2\")\n\n# Combine into one dataset\ncombined_samples <- bind_rows(sample1_labeled, sample2_labeled)\n\n# Calculate means\nmean1 <- mean(wildfire_sample$temperature, na.rm = TRUE)\nmean2 <- mean(wildfire_sample2$temperature, na.rm = TRUE)\n\n# Plot\nggplot(combined_samples, aes(x = temperature, fill = sample)) +\n  geom_histogram(binwidth = 2, alpha = 0.6, position = \"identity\", color = \"white\") +\n  geom_vline(xintercept = mean1, linetype = \"dashed\", color = \"#1f78b4\", linewidth = 1) +\n  geom_vline(xintercept = mean2, linetype = \"dashed\", color = \"#e31ad1\", linewidth = 1) +\n  scale_fill_manual(values = c(\"Sample 1\" = \"#1f78b4\", \"Sample 2\" = \"#e31ad1\")) +\n  labs(\n    title = \"Overlayed Histograms of Two Wildfire Samples\",\n    x = \"Temperature (°C)\",\n    y = \"Count\",\n    fill = \"Sample\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](sampling-fundamentals_files/figure-revealjs/unnamed-chunk-9-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n\n## Sampling variability\n\n- If we draw a different random sample, we get a different set of temperatures.\n- That means our point estimate (e.g., sample mean) will also likely change.\n- The changes in point estimates across samples is called **sampling variability**.\n\n## The sampling distribution\n\n- If we took many samples of the same size from the population and calculated the sample mean each time, the distribution of those means would form a **sampling distribution**.\n- In our case, the **sampling distribution of the sample mean** shows how the mean varies from sample to sample.\n\n## Estimating a sampling distribution \n\nImagine repeating our wildfire sampling process many times:\n\n1. Take a random sample of size $n = 100$\n2. Compute the sample mean temperature\n3. Repeat this 1000+ times\n\n## \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsampling_dist <- wildfire |>\n  rep_sample_n(size = 100, reps = 1000) |> \n\tgroup_by(replicate) |> \n\tsummarise(sample_mean = mean(temperature, na.rm=TRUE))\n\nhead(sampling_dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  replicate sample_mean\n      <int>       <dbl>\n1         1        21.0\n2         2        19.7\n3         3        19.6\n4         4        18.9\n5         5        18.6\n6         6        19.3\n```\n\n\n:::\n:::\n\n\n\n\n## \n\nA plot of the sample means allows us to visualize the sampling distribution of the sample mean.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sampling_dist, aes(x = sample_mean)) +\n  geom_histogram(binwidth = 0.5, color = \"white\", fill = \"steelblue\") +\n  labs(\n    title = \"Sampling Distribution of Mean Temperature\",\n    x = \"Sample Mean Temperature\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](sampling-fundamentals_files/figure-revealjs/unnamed-chunk-11-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Discuss\n\n- What patterns do you see in the distribution (think about shape, center and spread)?\n\n- How does this compare to the histogram of the full population?\n\n- What would happen if we increased or decreased the sample size?\n\n## Sample size\n\n- Now, let's see how increasing the sample size to 500 impacts the sampling distribution.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(200)\n\nsampling_dist_500 <- wildfire |>\n  rep_sample_n(size = 500, reps = 1000) |>\n\tgroup_by(replicate) |>\n  summarise(sample_mean = mean(temperature, na.rm = TRUE))\n```\n:::\n\n\n\n\n\n##\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggplot(sampling_dist_500, aes(x = sample_mean)) +\n  geom_histogram(binwidth = 0.1, fill = \"#1f78b4\", color = \"white\") +\n  labs(\n    title = \"Sampling Distribution of the Sample Mean (n = 500)\",\n    x = \"Sample Mean Temperature (°C)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](sampling-fundamentals_files/figure-revealjs/unnamed-chunk-13-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](sampling-fundamentals_files/figure-revealjs/unnamed-chunk-14-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n\n## Impact of sample size on sampling distributions\n\n- As sample size increases, the sampling distribution of the sample mean becomes narrower.\n\n- Larger samples result in sample means that are more closely clustered around the true population mean, whereas smaller samples show greater variability and a wider spread of sample means.\n\n\n## Why do we care?\n\n:::incremental\n- As a statistician, you don’t know the true population parameters, only your sample data!\n- From a sample, we can compute the **sample mean** $\\bar{x}$.\n- This is our best guess at the population mean $\\mu$, which is typically not observed. \n- But if we had taken a different sample, we might have gotten a different $\\bar{x}$. \n- The **standard error** helps us understand how much $\\bar{x}$ might vary from sample to sample.\n:::\n\n\n## Standard error\n\n- The **standard error (SE)** measures how much a sample statistic (like the mean) is expected to vary across different random samples.\n- It tells us how **precise** our estimate is.  \n\t- A smaller SE means our estimate is likely close to the population value  \n\t- A larger SE means more uncertainty in our estimate\n\n\n## Standard error of the sample mean\n\n- The standard error of the sample mean is estimated by:  \n\n$$SE(\\bar{x}) = \\frac{s}{\\sqrt{n}}$$\n\n\n where\n \n- $s$ is the sample standard deviation  \n- $n$ is the sample size  \n\nThis estimates the standard deviation of the sample mean across repeated random samples.\n\n## Computing the SE\n\nLet's calculate the standard error of the sample mean temperature from our wildfire sample ($n = 100$):\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nwildfire_sample |>\n  summarise(\n    n = sum(!is.na(temperature)),\n    s = sd(temperature, na.rm = TRUE),\n    se_xbar = s / sqrt(n)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  replicate     n     s se_xbar\n      <int> <int> <dbl>   <dbl>\n1         1    91  7.24   0.759\n```\n\n\n:::\n:::\n\n\n\n\nThis value tells us how much the sample mean is expected to vary across repeated samples of size 100.\n\n\n## What about other estimators?\n\n- Other estimators (like medians, proportions, or standard deviations) also have standard errors.  \n- Each has its own formula or method to estimate variability. \n- Today, we are focusing on the **standard error of the mean**, but the same general idea applies:\n  - Use the sample to estimate how much a statistic would vary across samples\n\n## Key Takeaways\n\n- A **population** includes all observations of interest; a **sample** is a subset we actually collect\n- A **parameter** describes the population (e.g., population mean $ \\mu $), but it's usually unknown  \n- A **statistic** (like the sample mean $\\bar{x}$) is a point estimate of the parameter, based on the sample \n- **Sampling variability** means statistics will vary from one random sample to another  \n- The **standard error (SE)** measures how much a statistic is expected to vary across samples  \n- A **smaller SE** means the estimate is more precise — and we can achieve that with a **larger sample size**",
    "supporting": [
      "sampling-fundamentals_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}